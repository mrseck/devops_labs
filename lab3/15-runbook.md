# Runbook - Troubleshooting Stack Monitoring

## Table des mati√®res
1. [V√©rification de l'√©tat des composants](#v√©rification-de-l√©tat-des-composants)
2. [Probl√®mes d'ingestion](#probl√®mes-dingestion)
3. [Probl√®mes de performance](#probl√®mes-de-performance)
4. [Probl√®mes de stockage](#probl√®mes-de-stockage)
5. [Probl√®mes r√©seau](#probl√®mes-r√©seau)
6. [Scripts de diagnostic](#scripts-de-diagnostic)

---

## V√©rification de l'√©tat des composants

### Commandes kubectl pour chaque namespace

```bash
# MinIO
kubectl get pods -n minio
kubectl logs -n minio deployment/minio
kubectl describe pod -n minio -l app=minio

# Loki
kubectl get pods -n loki
kubectl logs -n loki -l app=loki,component=distributor
kubectl logs -n loki -l app=loki,component=ingester
kubectl logs -n loki -l app=loki,component=querier

# Mimir
kubectl get pods -n mimir
kubectl logs -n mimir -l app=mimir,component=distributor
kubectl logs -n mimir -l app=mimir,component=ingester

# Tempo
kubectl get pods -n tempo
kubectl logs -n tempo -l app=tempo,component=distributor

# Alloy
kubectl get pods -n alloy-logs
kubectl get pods -n alloy-metrics
kubectl get pods -n alloy-traces

# Grafana
kubectl get pods -n grafana
kubectl logs -n grafana deployment/grafana
```

### Healthchecks

```bash
# MinIO
kubectl exec -n minio deployment/minio -- curl http://localhost:9000/minio/health/live

# Loki
kubectl exec -n loki deployment/loki-gateway -- curl http://localhost:80/ready

# Mimir
kubectl exec -n mimir deployment/mimir-gateway -- curl http://localhost:80/ready

# Tempo
kubectl exec -n tempo deployment/tempo-query-frontend -- curl http://localhost:3200/ready
```

---

## Probl√®mes d'ingestion

### Logs non visibles dans Loki

**Sympt√¥mes:**
- Les logs n'apparaissent pas dans Grafana
- Alloy Logs collecte mais n'envoie pas

**Diagnostics:**
```bash
# V√©rifier Alloy Logs
kubectl logs -n alloy-logs -l app=alloy-logs --tail=100

# V√©rifier Loki Distributor
kubectl logs -n loki -l app=loki,component=distributor --tail=100

# V√©rifier la connectivit√©
kubectl exec -n alloy-logs -l app=alloy-logs -- wget -O- http://loki-gateway.loki.svc.cluster.local:80/ready

# V√©rifier les m√©triques d'ingestion
# Dans Grafana: rate(loki_distributor_lines_received_total[5m])
```

**Solutions:**
1. V√©rifier la configuration Alloy (ConfigMap)
2. V√©rifier les labels et filtres
3. V√©rifier la connectivit√© r√©seau vers Loki
4. V√©rifier les quotas de ressources

### M√©triques manquantes dans Mimir

**Sympt√¥mes:**
- M√©triques non disponibles dans Grafana
- Alloy Metrics ne scrape pas

**Diagnostics:**
```bash
# V√©rifier Alloy Metrics
kubectl logs -n alloy-metrics -l app=alloy-metrics --tail=100

# V√©rifier les ServiceMonitors
kubectl get servicemonitors -A

# V√©rifier la connectivit√© vers Mimir
kubectl exec -n alloy-metrics -l app=alloy-metrics -- wget -O- http://mimir-gateway.mimir.svc.cluster.local:80/ready

# V√©rifier les m√©triques d'ingestion
# Dans Grafana: rate(mimir_distributor_samples_received_total[5m])
```

**Solutions:**
1. V√©rifier les ServiceMonitors et PodMonitors
2. V√©rifier les OrgID (pods vs nodes)
3. V√©rifier la configuration remote_write
4. V√©rifier les limites de rate limiting

### Traces perdues dans Tempo

**Sympt√¥mes:**
- Traces non visibles dans Grafana
- Alloy Traces ne re√ßoit pas

**Diagnostics:**
```bash
# V√©rifier Alloy Traces
kubectl logs -n alloy-traces -l app=alloy-traces --tail=100

# V√©rifier Tempo Distributor
kubectl logs -n tempo -l app=tempo,component=distributor --tail=100

# V√©rifier la connectivit√©
kubectl exec -n alloy-traces -l app=alloy-traces -- nc -zv tempo-distributor.tempo.svc.cluster.local 4317

# V√©rifier les m√©triques d'ingestion
# Dans Grafana: rate(tempo_distributor_spans_received_total[5m])
```

**Solutions:**
1. V√©rifier la configuration OTLP
2. V√©rifier les processors (k8sattributes, batch)
3. V√©rifier la connectivit√© r√©seau
4. V√©rifier l'√©chantillonnage

---

## Probl√®mes de performance

### Requ√™tes lentes dans Grafana

**Sympt√¥mes:**
- Timeout des requ√™tes
- Grafana non responsive

**Diagnostics:**
```bash
# V√©rifier les ressources
kubectl top pods -n loki
kubectl top pods -n mimir
kubectl top pods -n tempo

# V√©rifier les m√©triques de performance
# Loki: loki_query_frontend_query_latency_seconds
# Mimir: mimir_query_frontend_query_latency_seconds
```

**Solutions:**
1. Augmenter les replicas des queriers
2. Activer le cache dans query-frontend
3. Optimiser les requ√™tes (limiter la plage temporelle)
4. V√©rifier les HPA

### Queriers surcharg√©s

**Sympt√¥mes:**
- CPU > 80% sur les queriers
- Requ√™tes en timeout

**Solutions:**
```bash
# V√©rifier les HPA
kubectl get hpa -n loki
kubectl get hpa -n mimir
kubectl get hpa -n tempo

# Scale manuel si n√©cessaire
kubectl scale deployment loki-querier -n loki --replicas=5
```

### Ingesters √† saturation

**Sympt√¥mes:**
- Ingesters en erreur
- Donn√©es non persist√©es

**Solutions:**
1. Augmenter les ressources (CPU/RAM)
2. Augmenter le nombre de replicas
3. V√©rifier les limites d'ingestion
4. V√©rifier le stockage (PVC)

---

## Probl√®mes de stockage

### MinIO indisponible

**Sympt√¥mes:**
- Erreurs de connexion S3
- Donn√©es non accessibles

**Diagnostics:**
```bash
# V√©rifier l'√©tat du pod
kubectl get pods -n minio
kubectl describe pod -n minio -l app=minio

# V√©rifier le PVC
kubectl get pvc -n minio
kubectl describe pvc -n minio minio-storage

# V√©rifier les logs
kubectl logs -n minio deployment/minio
```

**Solutions:**
1. Red√©marrer le pod MinIO
2. V√©rifier le PVC et le StorageClass
3. V√©rifier l'espace disque disponible
4. Restaurer depuis backup si n√©cessaire

### Buckets pleins

**Sympt√¥mes:**
- Erreurs d'√©criture
- Stockage > 95%

**Solutions:**
```bash
# V√©rifier l'espace utilis√©
kubectl exec -n minio deployment/minio -- mc du /data

# Nettoyer les donn√©es expir√©es
# V√©rifier les r√©tentions configur√©es
# Forcer la compaction
```

### Compaction √©chou√©e

**Sympt√¥mes:**
- Compactor en erreur
- Donn√©es non compact√©es

**Diagnostics:**
```bash
# Loki Compactor
kubectl logs -n loki -l app=loki,component=compactor

# Mimir Compactor
kubectl logs -n mimir -l app=mimir,component=compactor

# Tempo Compactor
kubectl logs -n tempo -l app=tempo,component=compactor
```

**Solutions:**
1. V√©rifier les permissions S3
2. V√©rifier l'espace disponible
3. Red√©marrer le compactor
4. V√©rifier la configuration de compaction

---

## Probl√®mes r√©seau

### Communication inter-composants

**Sympt√¥mes:**
- Timeout de connexion
- Services non accessibles

**Diagnostics:**
```bash
# V√©rifier les Services
kubectl get svc -n loki
kubectl get svc -n mimir
kubectl get svc -n tempo

# Tester la connectivit√© DNS
kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup loki-gateway.loki.svc.cluster.local

# Tester la connectivit√© r√©seau
kubectl run -it --rm debug --image=busybox --restart=Never -- wget -O- http://loki-gateway.loki.svc.cluster.local:80/ready
```

**Solutions:**
1. V√©rifier les Services et Endpoints
2. V√©rifier les NetworkPolicies
3. V√©rifier la r√©solution DNS
4. V√©rifier les firewall rules

### NetworkPolicies bloquantes

**Sympt√¥mes:**
- Communication bloqu√©e entre namespaces

**Solutions:**
```bash
# Lister les NetworkPolicies
kubectl get networkpolicies -A

# V√©rifier les r√®gles
kubectl describe networkpolicy -n loki

# D√©sactiver temporairement pour test
kubectl delete networkpolicy -n loki --all
```

---

## Scripts de diagnostic

### Checklist de v√©rification rapide

```bash
#!/bin/bash
# 15-check-health.sh

echo "üîç V√©rification de la sant√© de la stack..."

# MinIO
echo "MinIO:"
kubectl get pods -n minio | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"

# Loki
echo "Loki:"
kubectl get pods -n loki | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"

# Mimir
echo "Mimir:"
kubectl get pods -n mimir | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"

# Tempo
echo "Tempo:"
kubectl get pods -n tempo | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"

# Alloy
echo "Alloy:"
kubectl get pods -n alloy-logs | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"
kubectl get pods -n alloy-metrics | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"
kubectl get pods -n alloy-traces | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"

# Grafana
echo "Grafana:"
kubectl get pods -n grafana | grep -v Running && echo "  ‚ö†Ô∏è  Probl√®me d√©tect√©" || echo "  ‚úÖ OK"
```

### Proc√©dures de rollback

```bash
# Rollback Loki
helm rollback loki -n loki

# Rollback Mimir
helm rollback mimir -n mimir

# Rollback Tempo
helm rollback tempo -n tempo

# Rollback Grafana
helm rollback grafana -n grafana
```

---

**Derni√®re mise √† jour:** 2024-01-15

