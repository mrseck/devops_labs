# Lab 2 - Gestion du Stockage et Surveillance PVC PostgreSQL

Ce lab met en place une infrastructure de stockage robuste pour PostgreSQL avec surveillance proactive de la saturation du PVC, en r√©ponse √† l'alerte critique du document de passation.

## üìã Objectif

Cr√©er une infrastructure qui pr√©vient automatiquement les probl√®mes de saturation du stockage pour la base de donn√©es PostgreSQL de Random.

## üèóÔ∏è Architecture

```
PostgreSQL Pod
    ‚Üì
PersistentVolumeClaim (PVC) - 50Gi (extensible √† 200Gi)
    ‚Üì
StorageClass: fast-ssd-expandable
    ‚Üì
Surveillance & Alertes (Prometheus + Grafana)
```

## üìÅ Structure des Fichiers

### Exercice 1 : StorageClass
- `01-storageclass.yaml` - StorageClass avec expansion activ√©e
-  01-storageclass_capture.png

### Exercice 2 : D√©ploiement PostgreSQL
- `02-postgres-configmap.yaml` - Configuration PostgreSQL
- `02-postgres-secret.yaml` - Secrets (utilisateur/mot de passe)
- `02-postgres-statefulset.yaml` - StatefulSet avec PVC et sidecar de monitoring
- `02-postgres-service-metrics.yaml` - Service pour exposer les m√©triques

### Exercice 3 : Surveillance Prometheus
- `03-servicemonitor.yaml` - ServiceMonitor pour Prometheus (avec label `team: monitoring`)
- `03-prometheus-instance.yaml` - Instance Prometheus 

### Exercice 4 : Alertes et Alertmanager
- `04-prometheusrule.yaml` - R√®gles d'alerte (70%, 85%, 95%, croissance) utilisant les m√©triques `pvc_*`
- `04-alertmanager-config.yaml` - Configuration Alertmanager avec routing par s√©v√©rit√©
- `04-webhook-receiver.yaml` - Webhook receiver pour recevoir et afficher les alertes
- `04-test-pvc-saturation.sh` - Script de test pour simuler la saturation du PVC

### Exercice 5 : Dashboard Grafana
- `05-grafana-dashboard.json` - Dashboard Grafana (JSON)
- `05-grafana-dashboard-configmap.yaml` - ConfigMap pour provisionner le dashboard

### Exercice 6 : Extension du PVC
- `06-extend-pvc.sh` - Script automatis√© pour √©tendre le PVC

### Exercice 7 : Strat√©gie de Backup
- `07-backup-snapshotclass.yaml` - VolumeSnapshotClass
- `07-backup-volumesnapshot.yaml` - Exemple de VolumeSnapshot
- `07-backup-cronjob.yaml` - CronJob pour pg_dump quotidien
- `07-restore-backup.sh` - Script de restauration

### Exercice 8 : Runbook
- `08-runbook.md` - Runbook complet de gestion de crise
- `08-emergency-cleanup.sh` - Script de nettoyage d'urgence

## üöÄ D√©ploiement

### Pr√©requis

- Cluster Kubernetes fonctionnel
- Namespace `random-db` cr√©√© (Lab 1)
- `kubectl` et `helm` install√©s
- Prometheus Operator install√©
- Acc√®s √† un syst√®me de stockage (local-path, NFS, ou cloud provider)

### √âtapes de D√©ploiement

1. **Cr√©er le StorageClass**
```bash
kubectl apply -f 01-storageclass.yaml
kubectl get storageclass
```

2. **D√©ployer PostgreSQL**
```bash
kubectl apply -f 02-postgres-configmap.yaml
kubectl apply -f 02-postgres-secret.yaml
kubectl apply -f 02-postgres-statefulset.yaml
kubectl apply -f 02-postgres-service-metrics.yaml

# V√©rifier le d√©ploiement
kubectl get pods -n random-db
kubectl get pvc -n random-db
```

3. **Configurer la Surveillance Prometheus**
```bash
# Cr√©er l'instance Prometheus
kubectl apply -f 03-prometheus-instance.yaml

# Configurer le ServiceMonitor (avec label team: monitoring requis)
kubectl apply -f 03-servicemonitor.yaml

# V√©rifier que Prometheus scrap les m√©triques
kubectl port-forward -n default prometheus-prometheus-0 9090:9090

# Dans un navigateur: http://localhost:9090
# Rechercher: pvc_usage_percent, pvc_capacity_bytes, pvc_used_bytes
```

4. **Configurer les Alertes**
```bash
# D√©ployer les r√®gles d'alerte Prometheus
kubectl apply -f 04-prometheusrule.yaml

# Configurer Alertmanager (optionnel, si Alertmanager est d√©ploy√©)
kubectl apply -f 04-alertmanager-config.yaml

# V√©rifier les alertes dans Prometheus
# http://localhost:9090/alerts
```

5. **Configurer Grafana**
```bash
kubectl apply -f 05-grafana-dashboard-configmap.yaml

# V√©rifier que Grafana d√©marrN
kubectl port-forward -n random-db svc/grafana 3000:3000
```

6. **Tester la Connexion PostgreSQL**
```bash
kubectl exec -it -n random-db postgres-0 -c postgres -- psql -U postgres -d randomdb
```

## üîß Utilisation

### Extension du PVC

```bash
chmod +x 06-extend-pvc.sh
./06-extend-pvc.sh random-db postgres-data 60Gi
```

### Nettoyage d'Urgence

```bash
chmod +x 08-emergency-cleanup.sh
./08-emergency-cleanup.sh random-db postgres-0
```

### Backup et Restauration

**Cr√©er un snapshot :**
```bash
kubectl apply -f 07-backup-volumesnapshot.yaml
```

**Cr√©er un backup pg_dump :**
```bash
kubectl apply -f 07-backup-cronjob.yaml
```

**Restaurer un backup :**
```bash
chmod +x 07-restore-backup.sh
./07-restore-backup.sh /backups/20240115/postgres_backup.dump.gz random-db postgres-0
```

## üìä Monitoring

### M√©triques Expos√©es

Le sidecar `pvc-monitor` dans le pod PostgreSQL expose les m√©triques suivantes (avec label `namespace="random-db"`) :

- `pvc_capacity_bytes{namespace="random-db"}` - Capacit√© totale du PVC en bytes
- `pvc_used_bytes{namespace="random-db"}` - Espace utilis√© en bytes
- `pvc_available_bytes{namespace="random-db"}` - Espace disponible en bytes
- `pvc_usage_percent{namespace="random-db"}` - Pourcentage d'utilisation (0-100)

**Acc√®s aux m√©triques :**
```bash
# Port-forward vers le pod PostgreSQL
kubectl port-forward -n random-db postgres-0 9091:9090

# Acc√©der aux m√©triques
curl http://localhost:9091/metrics
```

### Alertes Configur√©es

Les alertes utilisent les m√©triques `pvc_*` expos√©es par le sidecar :

1. **PVCUsageWarning** 
   - Seuil : 70% d'utilisation
   - S√©v√©rit√© : `warning`
   - Dur√©e : 5 minutes
   - Expression : `pvc_usage_percent{namespace="random-db"} > 70`

2. **PVCUsageCritical**
   - Seuil : 85% d'utilisation
   - S√©v√©rit√© : `critical`
   - Dur√©e : 2 minutes
   - Expression : `pvc_usage_percent{namespace="random-db"} > 85`

3. **PVCUsageEmergency**
   - Seuil : 95% d'utilisation
   - S√©v√©rit√© : `emergency`
   - Dur√©e : 1 minute
   - Expression : `pvc_usage_percent{namespace="random-db"} > 95`

4. **PVCGrowthRate**
   - D√©tection : Projection de saturation dans moins de 7 jours
   - S√©v√©rit√© : `warning`
   - Dur√©e : 1 heure
   - Condition : Utilisation actuelle > 50% ET projection de saturation < 7 jours
   - Expression : `predict_linear(pvc_used_bytes{namespace="random-db"}[7d], 7*24*3600) > pvc_capacity_bytes{namespace="random-db"} AND pvc_usage_percent{namespace="random-db"} > 50`

### Configuration Alertmanager

L'Alertmanager route les alertes selon leur s√©v√©rit√© :
- **Emergency** ‚Üí `emergency-team` (r√©p√©tition toutes les 5 minutes)
- **Critical** ‚Üí `oncall-team` (r√©p√©tition toutes les 30 minutes)
- **Warning** ‚Üí `monitoring-team` (r√©p√©tition toutes les 4 heures)
- **Default** ‚Üí Webhook receiver (pour les tests)

### Acc√®s aux Dashboards

**Prometheus :**
```bash
# Port-forward vers Prometheus
kubectl port-forward -n default svc/prometheus-web 9090:9090
# Ou via NodePort (port 30090)
```
- Interface web : `http://localhost:9090`
- Alertes : `http://localhost:9090/alerts`
- Graph : `http://localhost:9090/graph`
- Targets : `http://localhost:9090/targets`

**Webhook Receiver (pour les tests) :**
```bash
# Voir les logs du webhook receiver
kubectl logs -n random-db -l app=webhook-receiver -f
```

**Grafana :**
- Interface : `http://grafana.example.com` (dashboard: "PostgreSQL PVC Monitoring")

## üß™ Tests

### Test de Charge

Simuler une mont√©e en charge du stockage :

```bash
# Cr√©er une table de test et ins√©rer des donn√©es
kubectl exec -it -n random-db postgres-0 -c postgres -- psql -U postgres -d randomdb <<EOF
CREATE TABLE test_data AS 
SELECT generate_series(1, 1000000) AS id, 
       md5(random()::text) AS data;
EOF

# V√©rifier l'utilisation
kubectl exec -n random-db postgres-0 -c postgres -- df -h /var/lib/postgresql/data
```

### Test de Saturation du PVC

**Simuler la saturation du PVC :**
```bash
# Utiliser le script de test fourni
chmod +x 04-test-pvc-saturation.sh
./04-test-pvc-saturation.sh

# Ou manuellement
kubectl exec -n random-db postgres-0 -- bash -c '
  for i in {1..100}; do
    dd if=/dev/zero of=/var/lib/postgresql/data/testfile_$i.dat bs=1M count=100 2>/dev/null
    echo "Fichier $i cr√©√© ($(df -h /var/lib/postgresql/data | tail -1 | awk "{print \$5}"))"
    sleep 2
  done
'
```

**V√©rifier le d√©clenchement des alertes :**
```bash
# 1. V√©rifier les m√©triques dans Prometheus
# http://localhost:9090/graph?g0.expr=pvc_usage_percent{namespace="random-db"}

# 2. V√©rifier les alertes
# http://localhost:9090/alerts

# 3. Surveiller les logs du webhook receiver
kubectl logs -n random-db -l app=webhook-receiver -f

# 4. V√©rifier l'utilisation du PVC
kubectl exec -n random-db postgres-0 -c postgres -- df -h /var/lib/postgresql/data
```

**Tests √† effectuer :**
1. Remplir progressivement le PVC jusqu'√† 70% (alerte Warning)
2. Continuer jusqu'√† 85% (alerte Critical)
3. Poursuivre jusqu'√† 95% (alerte Emergency)
4. V√©rifier le d√©clenchement des alertes aux bons seuils
5. Tester la proc√©dure d'extension sous charge
6. Valider la restauration depuis un backup

## üìö Documentation

- **Runbook** : Voir `08-runbook.md` pour les proc√©dures de gestion de crise
- **QCM** : R√©ponses dans le PDF du Lab 2

## ‚ö†Ô∏è Notes Importantes

1. **Adapter le StorageClass** : Modifier le `provisioner` dans `01-storageclass.yaml` selon votre environnement (local-path pour k3s, ebs.csi.aws.com pour AWS, etc.)

2. **S√©curit√©** : Changer le mot de passe PostgreSQL dans `02-postgres-secret.yaml` en production !

3. **Monitoring** : 
   - Le sidecar de monitoring utilise Python pour exposer les m√©triques Prometheus
   - Les m√©triques incluent le label `namespace` pour faciliter le filtrage
   - Le ServiceMonitor doit avoir le label `team: monitoring` pour √™tre s√©lectionn√© par Prometheus
   - La PrometheusRule doit avoir le label `prometheus: default` correspondant √† l'instance Prometheus
   - Pour un environnement de production, consid√©rer l'utilisation d'un exporter Prometheus d√©di√© (node-exporter, etc.)

4. **Configuration Prometheus** :
   - L'instance Prometheus dans `04-prometheus-instance.yaml` utilise le s√©lecteur `team: monitoring` pour les ServiceMonitors
   - Le `ruleSelector: {}` permet de charger toutes les PrometheusRules (peut √™tre restreint si n√©cessaire)
   - Le ServiceMonitor dans `03-servicemonitor.yaml` doit avoir le label `team: monitoring`

5. **Backups** : Les backups sont configur√©s pour s'ex√©cuter quotidiennement √† 2h du matin. Ajuster selon vos besoins.

6. **Tests d'alertes** : 
   - Le script `04-test-pvc-saturation.sh` g√©n√®re environ 10GB de donn√©es de test
   - Pour un PVC de 50Gi, cela repr√©sente environ 20% d'utilisation
   - Pour tester les alertes, vous devrez peut-√™tre ajuster le script ou cr√©er plus de donn√©es
   - N'oubliez pas de nettoyer les fichiers de test apr√®s les tests : `kubectl exec -n random-db postgres-0 -- rm -f /var/lib/postgresql/data/testfile_*.dat`

## üîç Validation

Checklist de validation :

**Exercice 1-2 : Infrastructure de base**
- [ ] StorageClass configur√© avec expansion activ√©e
- [ ] PostgreSQL d√©ploy√© avec StatefulSet et PVC
- [ ] Sidecar de monitoring op√©rationnel et exposant les m√©triques

**Exercice 3 : Surveillance**
- [ ] ServiceMonitor cr√©√© avec le label `team: monitoring`
- [ ] Instance Prometheus d√©ploy√©e
- [ ] M√©triques `pvc_*` visibles dans Prometheus (avec label `namespace`)
- [ ] ServiceMonitor d√©tect√© par Prometheus (v√©rifier dans `/targets`)

**Exercice 4 : Alertes**
- [ ] PrometheusRule d√©ploy√©e avec le label `prometheus: default`
- [ ] R√®gles d'alerte charg√©es dans Prometheus (v√©rifier dans `/rules`)
- [ ] Alertes visibles dans l'interface Prometheus (`/alerts`)
- [ ] Webhook receiver d√©ploy√© et fonctionnel
- [ ] Configuration Alertmanager appliqu√©e (si Alertmanager est d√©ploy√©)
- [ ] Test de saturation effectu√© et alertes d√©clench√©es aux bons seuils

**Exercice 5-8 : Dashboard et proc√©dures**
- [ ] Dashboard Grafana fonctionnel
- [ ] Proc√©dure d'extension document√©e et test√©e
- [ ] Strat√©gie de backup op√©rationnelle
- [ ] Runbook complet et accessible

## üìû Support

Pour toute question ou probl√®me, consulter :
- Le runbook (`08-runbook.md`)
- La documentation Kubernetes
- L'√©quipe DevOps

---

## üîß D√©pannage

### Les m√©triques ne sont pas scrap√©es par Prometheus

1. V√©rifier que le ServiceMonitor a le label `team: monitoring` :
```bash
kubectl get servicemonitor -n random-db postgres-pvc-monitor -o yaml | grep -A 5 labels
```

2. V√©rifier que Prometheus d√©tecte le ServiceMonitor :
```bash
# Port-forward vers Prometheus
kubectl port-forward -n default svc/prometheus-web 9090:9090
# Aller sur http://localhost:9090/targets
```

3. V√©rifier que le service de m√©triques existe et pointe vers les pods :
```bash
kubectl get svc -n random-db postgres-metrics
kubectl get endpoints -n random-db postgres-metrics
```

### Les alertes ne se d√©clenchent pas

1. V√©rifier que les m√©triques sont disponibles :
```bash
# Dans Prometheus, ex√©cuter la requ√™te :
pvc_usage_percent{namespace="random-db"}
```

2. V√©rifier que la PrometheusRule est charg√©e :
```bash
kubectl get prometheusrule -n random-db postgres-pvc-alerts
# Dans Prometheus : http://localhost:9090/rules
```

3. V√©rifier que le label `prometheus: default` correspond √† l'instance Prometheus :
```bash
kubectl get prometheus -n default prometheus -o yaml | grep -A 2 labels
kubectl get prometheusrule -n random-db postgres-pvc-alerts -o yaml | grep prometheus
```

4. Tester manuellement une r√®gle d'alerte :
```bash
# Dans Prometheus, ex√©cuter :
pvc_usage_percent{namespace="random-db"} > 70
```

### Les m√©triques n'ont pas de label namespace

1. Red√©marrer le pod PostgreSQL pour recharger le sidecar avec la nouvelle configuration :
```bash
kubectl rollout restart statefulset/postgres -n random-db
```

2. V√©rifier que la variable d'environnement NAMESPACE est d√©finie :
```bash
kubectl exec -n random-db postgres-0 -c pvc-monitor -- env | grep NAMESPACE
```

---

**Derni√®re mise √† jour** : 2024-11-07

